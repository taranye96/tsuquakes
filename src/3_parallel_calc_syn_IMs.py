#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jan 30 00:13:49 2020

@author: tnye
"""

###############################################################################
# Parallelized script that goes through synethic waveforms generated by
# FakeQuakes, calculates IMs and spectra, and stores it all in a flatefile.
# Script also produces comparison plots betwen synthetic and observed waveforms
# and spectra.  
###############################################################################

# Standard library Imports 
import sys
from sys import stdout
from mpi4py import MPI
from glob import glob
from os import makedirs, path
import numpy as np
from numpy import genfromtxt
import pandas as pd
from obspy import read, UTCDateTime, Stream

# Local Imports
sys.path.insert(0, '/Users/tnye/tsuquakes/code/tsuquakes/src/')
import tsueqs_main_fns as tmf
import gnss_noise_fns as gnss_noise
import IM_fns
import comparison_fns as comp
sys.path.insert(0, '/Users/tnye/tsuquakes/code/tsuquakes/src/processing/')
import signal_average_fns as avg
from rotd50 import compute_rotd50



############################# Set up parameters ##############################

# project_list = np.array([['final_runs_m7.8','standard']])

# project_list = np.array([['final_runs_m7.8','rt1.0x_sf0.37'],
#                           ['final_runs_m7.8','rt1.0x_sf0.4'],
#                           ['final_runs_m7.8','rt1.0x_sf0.43'],
#                           ['final_runs_m7.8','rt1.0x_sf0.46'],
#                           ['final_runs_m7.8','rt1.0x_sf0.49'],
#                           ['final_runs_m7.8','rt1.1x_sf0.37'],
#                           ['final_runs_m7.8','rt1.1x_sf0.4'],
#                           ['final_runs_m7.8','rt1.1x_sf0.43'],
#                           ['final_runs_m7.8','rt1.1x_sf0.46'],
#                           ['final_runs_m7.8','rt1.1x_sf0.49'],
#                           ['final_runs_m7.8','rt1.2x_sf0.37'],
#                           ['final_runs_m7.8','rt1.2x_sf0.4'],
#                           ['final_runs_m7.8','rt1.2x_sf0.43'],
#                           ['final_runs_m7.8','rt1.2x_sf0.46'],
#                           ['final_runs_m7.8','rt1.2x_sf0.49'],    
#                           ['final_runs_m7.8','rt1.3x_sf0.37'],
#                           ['final_runs_m7.8','rt1.3x_sf0.4'],
#                           ['final_runs_m7.8','rt1.3x_sf0.43'],
#                           ['final_runs_m7.8','rt1.3x_sf0.46'],
#                           ['final_runs_m7.8','rt1.3x_sf0.49'],
#                           ['final_runs_m7.8','rt1.4x_sf0.37'],
#                           ['final_runs_m7.8','rt1.4x_sf0.4'],
#                           ['final_runs_m7.8','rt1.4x_sf0.43'],
#                           ['final_runs_m7.8','rt1.4x_sf0.46'],
#                           ['final_runs_m7.8','rt1.4x_sf0.49'],
#                           ['final_runs_m7.8','rt1.5x_sf0.37'],
#                           ['final_runs_m7.8','rt1.5x_sf0.4'],
#                           ['final_runs_m7.8','rt1.5x_sf0.43'],
#                           ['final_runs_m7.8','rt1.5x_sf0.46'],
#                           ['final_runs_m7.8','rt1.5x_sf0.49'],
#                           ['final_runs_m7.8','rt1.6x_sf0.37'],
#                           ['final_runs_m7.8','rt1.6x_sf0.4'],
#                           ['final_runs_m7.8','rt1.6x_sf0.43'],
#                           ['final_runs_m7.8','rt1.6x_sf0.46'],
#                           ['final_runs_m7.8','rt1.6x_sf0.49'],
#                           ['final_runs_m7.8','rt1.7x_sf0.37'],
#                           ['final_runs_m7.8','rt1.7x_sf0.4'],
#                           ['final_runs_m7.8','rt1.7x_sf0.43'],
#                           ['final_runs_m7.8','rt1.7x_sf0.46'],
#                           ['final_runs_m7.8','rt1.7x_sf0.49'],
#                           ['final_runs_m7.8','rt1.8x_sf0.37'],
#                           ['final_runs_m7.8','rt1.8x_sf0.4'],
#                           ['final_runs_m7.8','rt1.8x_sf0.43'],
#                           ['final_runs_m7.8','rt1.8x_sf0.46'],
#                           ['final_runs_m7.8','rt1.8x_sf0.49'],
#                           ['final_runs_m7.8','rt1.9x_sf0.37'],
#                           ['final_runs_m7.8','rt1.9x_sf0.4'],
#                           ['final_runs_m7.8','rt1.9x_sf0.43'],
#                           ['final_runs_m7.8','rt1.9x_sf0.46'],
#                           ['final_runs_m7.8','rt1.9x_sf0.49'],
#                           ['final_runs_m7.8','rt2.0x_sf0.37'],
#                           ['final_runs_m7.8','rt2.0x_sf0.4'],
#                           ['final_runs_m7.8','rt2.0x_sf0.43'],
#                           ['final_runs_m7.8','rt2.0x_sf0.46'],
#                           ['final_runs_m7.8','rt2.0x_sf0.49'],
#                           ['final_runs_m7.8','rt2.1x_sf0.37'],
#                           ['final_runs_m7.8','rt2.1x_sf0.4'],
#                           ['final_runs_m7.8','rt2.1x_sf0.43'],
#                           ['final_runs_m7.8','rt2.1x_sf0.46'],
#                           ['final_runs_m7.8','rt2.1x_sf0.49'],
#                           ['final_runs_m7.8','rt2.2x_sf0.37'],
#                           ['final_runs_m7.8','rt2.2x_sf0.4'],
#                           ['final_runs_m7.8','rt2.2x_sf0.43'],
#                           ['final_runs_m7.8','rt2.2x_sf0.46'],
#                           ['final_runs_m7.8','rt2.2x_sf0.49'],
#                           ['final_runs_m7.8','rt2.3x_sf0.37'],
#                           ['final_runs_m7.8','rt2.3x_sf0.4'],
#                           ['final_runs_m7.8','rt2.3x_sf0.43'],
#                           ['final_runs_m7.8','rt2.3x_sf0.46'],
#                           ['final_runs_m7.8','rt2.3x_sf0.49'],
#                           ['final_runs_m7.8','standard']
#                           ])


# project_list = np.array([['ideal_runs_m7.8','standard']
#                           ])


project_list = np.array([
                          ['test_runs_m7.8/stress_drop','sd0.1'],
                          ['test_runs_m7.8/stress_drop','sd1.0'],
                          ['test_runs_m7.8/stress_drop','sd2.0'],
                          ['test_runs_m7.8/risetime','rt2x'],
                          ['test_runs_m7.8/risetime','rt3x'],
                          ['test_runs_m7.8/vrupt','sf0.3'],
                          ['test_runs_m7.8/vrupt','sf0.4'],
                          ['test_runs_m7.8','standard']])

# project_list = np.array([['test_runs_m7.8','standard']
#                           ])


# project_list = np.array([['stress_drop','sd2.0'],
#                           ['stress_drop','sd1.75'],
#                           ['stress_drop','sd1.5'],
#                           ['stress_drop','sd1.25']
#                           ])

# project_list = np.array([['stress_drop','sd1.0'],
#                           ['stress_drop','sd0.75'],
#                           ['stress_drop','sd0.5']])


# project_list = np.array([
#                           ['vrupt','sf0.3'],
#                           ['vrupt','sf0.4'],
#                           ['risetime','rt2x'],
#                           ['risetime','rt3x'],
#                           ])


# home = '/Users/tnye/FakeQuakes/simulations/test_runs_m7.8'
home = '/Users/tnye/FakeQuakes/simulations'
home_dir = f'{home}'

# data_types = ['gnss','sm']
data_types = ['sm']
avg_comp = '3-comp'

############################# Start Parallelization ###########################

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()

ncpus = size

if rank == 0:
    sendbuf = np.arange(float(len(project_list)))

    # count: the size of each sub-task
    ave, res = divmod(sendbuf.size, ncpus)
    count = [ave + 1 if p < res else ave for p in range(ncpus)]
    count = np.array(count)

    # displacement: the starting index of each sub-task
    displ = [sum(count[:p]) for p in range(ncpus)]
    displ = np.array(displ)
else:
    sendbuf = None
    # initialize count on worker processes
    count = np.zeros(ncpus, dtype=int)
    displ = None

# broadcast count
comm.Bcast(count, root=0)

# initialize recvbuf on all processes
recvbuf = np.zeros(count[rank])

comm.Scatterv([sendbuf, count, displ, MPI.DOUBLE], recvbuf, root=0)
print('Rank: '+str(rank)+' received data='+str(recvbuf))


################################ Observed data ################################

obs_wf_dir = '/Users/tnye/tsuquakes/data/waveforms/average/flatfiles'

# Observed spectra using full waveforms
acc_obs_spec_df = pd.read_csv('/Users/tnye/tsuquakes/data/obs_avg_spectra/acc_binned_spec.csv')
acc_obs_freqs = np.array(acc_obs_spec_df.iloc[:,:int(acc_obs_spec_df.shape[1]/2)])
acc_obs_spec = np.array(acc_obs_spec_df.iloc[:,int(acc_obs_spec_df.shape[1]/2):])

disp_obs_spec_df = pd.read_csv('/Users/tnye/tsuquakes/data/obs_avg_spectra/disp_binned_spec.csv')
disp_obs_freqs = np.array(disp_obs_spec_df.iloc[:,:int(disp_obs_spec_df.shape[1]/2)])
disp_obs_spec = np.array(disp_obs_spec_df.iloc[:,int(disp_obs_spec_df.shape[1]/2):])


# Observed spectra using trimmed waveforms
acc_obs_spec_trim_df = pd.read_csv('/Users/tnye/tsuquakes/data/obs_avg_spectra/acc_binned_spec_trim.csv')
acc_obs_freqs_trim = np.array(acc_obs_spec_trim_df.iloc[:,:int(acc_obs_spec_trim_df.shape[1]/2)])
acc_obs_spec_trim = np.array(acc_obs_spec_trim_df.iloc[:,int(acc_obs_spec_trim_df.shape[1]/2):])

disp_obs_spec_trim_df = pd.read_csv('/Users/tnye/tsuquakes/data/obs_avg_spectra/disp_binned_spec_trim.csv')
disp_obs_freqs_trim = np.array(disp_obs_spec_trim_df.iloc[:,:int(disp_obs_spec_trim_df.shape[1]/2)])
disp_obs_spec_trim = np.array(disp_obs_spec_trim_df.iloc[:,int(disp_obs_spec_trim_df.shape[1]/2):])


############################### Do Calculations ###############################

# Table of earthquake data
data_dir = '/Users/tnye/tsuquakes/data'
eq_table_path = f'{data_dir}/misc/events.csv'   
eq_table = pd.read_csv(eq_table_path)

### Get event data ###
origin = pd.to_datetime('2010-10-25T14:42:22')
eventname = 'Mentawai2010'
country = eq_table['Country'][11]
origintime = eq_table['Origin Time (UTC)*'][11]
hyplon = eq_table['Longitude'][11]
hyplat = eq_table['Latitude'][11]
hypdepth = eq_table['Depth (km)'][11]
mw = eq_table['Mw'][11]
m0 = 10**(mw*(3/2.) + 9.1)
mechanism = eq_table['Mechanism'][11]  

for index in recvbuf:
    
    parameter = project_list[int(index)][0]
    project = project_list[int(index)][1]
    
    print(f'Rank {rank} working on {project}')
    
    # if project == 'standard':
    #     param_dir = f'{home_dir}/{project}' 
    # else: 
    #     param_dir = f'{home_dir}/{parameter}/{project}'
    param_dir = f'{home_dir}/{parameter}/{project}'

    
    rupture_list = genfromtxt(f'{param_dir}/data/ruptures.list',dtype='U')
    
    for rupture in rupture_list:
    
        run = rupture.rsplit('.', 1)[0]
        
        # print(f'Rank {rank} working on {project} {run}')
    
        # Set up folder for flatfile
        if not path.exists(f'{param_dir}/flatfiles'):
            makedirs(f'{param_dir}/flatfiles')
        if not path.exists(f'{param_dir}/flatfiles/IMs'):
            makedirs(f'{param_dir}/flatfiles/IMs')
            
        # Synthetic miniseed dir
        wf_dir = f'{param_dir}/output/waveforms/{run}/'
        
        # Gather displacement and strong motion files
        if 'gnss' in data_types:
            gnss_stations = pd.read_csv(f'{param_dir}/data/station_info/gnss_clean.gflist',delimiter='\t')['#station'].values
            for i in range(len(gnss_stations)):
                gnss_stations[i] = gnss_stations[i].strip(' ')
                gnss_files = np.array(sorted(glob(wf_dir + '*LY*.sac')))
                rm_ind = []
                for j in range(len(gnss_files)):
                    if gnss_files[j].split('/')[-1].split('.')[0] not in gnss_stations:
                        rm_ind.append(j)
                gnss_files = np.delete(gnss_files, rm_ind)
            gnss_flatfile_path = f'{param_dir}/flatfiles/IMs/{run}_gnss.csv'
             
        if 'sm' in data_types:
            sm_files = np.array(sorted(glob(wf_dir + '*.bb*.sac')))
            if len(sm_files)==0:
                sm_files = np.array(sorted(glob(wf_dir + '*.mpi.sac')))
            sm_flatfile_path = f'{param_dir}/flatfiles/IMs/{run}_sm.csv'
        
        # Filtering
        threshold = 0.0
        fcorner_high = 1/15.                     # Frequency at which to high pass filter
        fcorner_low = 0.4
        order = 2                                # Number of poles for filter  
        
        
        ##################### Data Processing and Calculations ####################
            
        for data in data_types:
    
            # Create lists for of the event and station info for the df
            eventnames = np.array([])
            countries = np.array([])
            origintimes = np.array([])
            hyplons = np.array([])
            hyplats = np.array([])
            hypdepths = np.array([])
            mws = np.array([])
            m0s = np.array([])
            mechanisms = np.array([])
            networks = np.array([])
            stations = np.array([])
            stn_type_list = np.array([])
            stlons = np.array([])
            stlats = np.array([])
            stelevs = np.array([])
            hypdist_list = np.array([])
            instrument_codes = np.array([])
            E_Td_list = np.array([])
            N_Td_list = np.array([])
            Z_Td_list = np.array([])
            horiz_Td_list = np.array([])
            comp3_Td_list = np.array([])
            pga_list = np.array([])
            pgv_list = np.array([])
            pgd_list = np.array([])
            tPGD_list = np.array([])
            tPGA_list = np.array([])
        
            if data == 'gnss':
                metadata_file = data_dir + '/' + eventname + '/' + eventname + '_disp.chan'
                files = gnss_files
                IMs = ['pgd']
                filtering = 'lowpass'
                station_names = np.genfromtxt('/Users/tnye/FakeQuakes/files/stn_info/gnss_clean.gflist',dtype=str)[:,0]
                
            elif data == 'sm':
                metadata_file = data_dir + '/' + eventname + '/' + eventname + '_sm.chan'
                files = sm_files
                IMs = ['pga', 'pgv']
                filtering = 'highpass'
                station_names = np.genfromtxt('/Users/tnye/FakeQuakes/files/stn_info/sm_close.gflist',dtype=str)[:,0]
    
            metadata = pd.read_csv(metadata_file, sep='\t', header=0,
                                  names=['net', 'sta', 'loc', 'chan', 'lat',
                                          'lon', 'elev', 'samplerate', 'gain', 'units'])
        
            # There might be white spaces in the station name, so remove those
            metadata.sta = metadata.sta.astype(str)
            metadata.sta = metadata.sta.str.replace(' ','')
    
            # Create lists to add station names, channels, and miniseed files to 
            stn_list = []
            channel_list = []
            mseed_list = []
            
            # Group all files by station
            N = 3
            stn_files = [files[n:n+N] for n in range(0, len(files), N)]
            
            # Lists to make spectra and wf comparison plots
            syn_freqs = []
            syn_spec = []
            syn_freqs_trim = []
            syn_spec_trim = []
            syn_times = []
            syn_amps_E = []
            syn_amps_N = []
            syn_amps_Z = []
            syn_amps_avg = []
            hypdists = []
            
            # print(f'...working on processing {parameter} {project} data')
            
            # Loop over the stations for this earthquake, and start to run the computations:        
            for i, group in enumerate(stn_files):
                
                stn = group[0].split('/')[-1].split('.')[0]
                
                if stn in station_names:
                
                
                    stn_list.append(stn)
                    components = np.array([])
                    
                    for mseed in group:
                        # Get the instrument component (E,N,Z) for this station
                        # channel = mseed.split('/')[-1].split('.sac')[0].split('.')[1]
                        channel = mseed.split('/')[-1].split('.sac')[0].split('.')[-1]
                        components = np.append(components,channel[2])
                    
                    # Get the metadata for this station from the chan file - put it into
                    #    a new dataframe and reset the index so it starts at 0
                    station_metadata = metadata[metadata.sta == stn].reset_index(drop=True)       # what is going on here
              
                    # Pull out the data. Take the first row of the subset dataframe, 
                    #    assuming that the gain, etc. is always the same:
                    stnetwork = station_metadata.loc[0].net
                    stlon = station_metadata.loc[0].lon
                    stlat = station_metadata.loc[0].lat
                    stelev = station_metadata.loc[0].elev
                    stsamprate = station_metadata.loc[0].samplerate
                    stgain = station_metadata.loc[0].gain
          
            
                    ##################### Start computations ######################        
                    
                    # Compute the hypocentral distance
                    hypdist = tmf.compute_rhyp(stlon,stlat,stelev,hyplon,hyplat,hypdepth)
            
                    # Append the earthquake and station info for this station
                    eventnames = np.append(eventnames,eventname)
                    countries = np.append(countries,country)
                    origintimes = np.append(origintimes,origintime)
                    hyplons = np.append(hyplons,hyplon)
                    hyplats = np.append(hyplats,hyplat)
                    hypdepths = np.append(hypdepths,hypdepth)
                    mws = np.append(mws,mw)
                    m0s = np.append(m0s,m0)
                    mechanisms = np.append(mechanisms,mechanism)
                    networks = np.append(networks,stnetwork)
                    stations = np.append(stations,stn)
                    stlons = np.append(stlons,stlon)
                    stlats = np.append(stlats,stlat)
                    stelevs = np.append(stelevs,stelev)
                    hypdist_list = np.append(hypdist_list,hypdist)
                    if data == 'gnss':
                        stn_type_list = np.append(stn_type_list, 'GNSS')
                    elif data == 'sm':
                        stn_type_list = np.append(stn_type_list, 'SM')
                    
                    # List for all spectra at station
                    station_spec = []
                    
                    # Set up directories for filtered acceleration data 
                    if not path.exists(f'{param_dir}/processed_wfs/acc/{run}'):
                            makedirs(f'{param_dir}/processed_wfs/acc/{run}')
                    # Set up directories for filtered displacement data
                    if not path.exists(f'{param_dir}/processed_wfs/disp/{run}'):
                            makedirs(f'{param_dir}/processed_wfs/disp/{run}')
                    # Set up directories for filtered displacement data
                    if not path.exists(f'{param_dir}/processed_wfs/disp_noise/{run}'):
                            makedirs(f'{param_dir}/processed_wfs/disp_noise/{run}')
                    
                    ########## East component ##########
            
                    # Find and read in East component
                    E_index = np.where(components=='E')[0][0]
                    E_raw = read(group[E_index])
            
                    # High pass filter strong motion data at fcorner specified above
                    if filtering == 'lowpass':
                        E_filt = tmf.lowpass(E_raw,fcorner_low,stsamprate,order,zerophase=True)
                        
                    elif filtering == 'highpass':
                        E_filt = tmf.highpass(E_raw,fcorner_high,stsamprate,order,zerophase=True)
                    
                    E_record = E_filt
                    
                    if data == 'sm':
                        E_record[0].stats.channel = 'HNE'
                        E_record_filename = f'{param_dir}/processed_wfs/acc/{run}/{stn}.{E_record[0].stats.channel}.mseed' 
                    if data == 'gnss':
                        E_record[0].stats.channel = 'LYE'
                        E_record_filename = f'{param_dir}/processed_wfs/disp/{run}/{stn}.{E_record[0].stats.channel}.mseed' 
                    
                    E_record[0].write(E_record_filename, format='MSEED')
                    
                    # Get the duration, stream file time of start, and time of stop of shaking
                    E_Td, E_start, E_end = tmf.determine_Td(threshold,E_record)      
                    E_Td_list = np.append(E_Td_list,E_Td)
            
                    ########## North component ##########
            
                    # Find and read in North component 
                    N_index = np.where(components=='N')[0][0]
                    N_raw = read(group[N_index])
            
                    # High pass filter strong motion data at fcorner specified above
                    if filtering == 'lowpass':
                        N_filt = tmf.lowpass(N_raw,fcorner_low,stsamprate,order,zerophase=True)
                        
                    elif filtering == 'highpass':
                        N_filt = tmf.highpass(N_raw,fcorner_high,stsamprate,order,zerophase=True)
                    
                    N_record = N_filt
                        
                    if data == 'sm':
                        N_record[0].stats.channel = 'HNN'
                        N_record_filename = f'{param_dir}/processed_wfs/acc/{run}/{stn}.{N_record[0].stats.channel}.mseed' 
                    if data == 'gnss':
                        N_record[0].stats.channel = 'LYN'
                        N_record_filename = f'{param_dir}/processed_wfs/disp/{run}/{stn}.{N_record[0].stats.channel}.mseed' 
                       
                    N_record[0].write(N_record_filename, format='MSEED')
                    
                    # Get the duration, stream file time of start, and time of stop of shaking
                    N_Td, N_start, N_end = tmf.determine_Td(threshold,N_record)      
                    N_Td_list = np.append(N_Td_list,N_Td)
            
                    ########## Vertical component ##########
            
                    # Find and read in vertical component
                    Z_index = np.where(components=='Z')[0][0]                       
                    Z_raw = read(group[Z_index])
            
                    # High pass filter strong motion data at fcorner specified above
                    if filtering == 'lowpass':
                        Z_filt = tmf.lowpass(Z_raw,fcorner_low,stsamprate,order,zerophase=True)
                        
                    elif filtering == 'highpass':
                        Z_filt = tmf.highpass(Z_raw,fcorner_high,stsamprate,order,zerophase=True)
                    
                    Z_record = Z_filt
                        
                    if data == 'sm':
                        Z_record[0].stats.channel = 'HNZ'
                        Z_record_filename = f'{param_dir}/processed_wfs/acc/{run}/{stn}.{Z_record[0].stats.channel}.mseed' 
                    if data == 'gnss':
                        Z_record[0].stats.channel = 'LYZ'
                        Z_record_filename = f'{param_dir}/processed_wfs/disp/{run}/{stn}.{Z_record[0].stats.channel}.mseed' 
                        
                    Z_record[0].write(Z_record_filename, format='MSEED')
                    
                    # Get the duration, stream file time of start, and time of stop of shaking
                    Z_Td, Z_start, Z_end = tmf.determine_Td(threshold,Z_record)  
                    Z_Td_list = np.append(Z_Td_list,Z_Td)    
                    
                    # Add noise to GNSS
                    if data == 'gnss':
                        # st_E_noisy,st_N_noisy,st_Z_noisy = gnss_noise.add_gnss_noise(E_raw,N_raw,Z_raw,noise_perc)
                        st_E_noisy,st_N_noisy,st_Z_noisy = gnss_noise.add_real_gnss_noise(E_raw,N_raw,Z_raw)
                        
                        st_E_noisyfilt = tmf.lowpass(st_E_noisy,fcorner_low,stsamprate,order,zerophase=True)
                        st_N_noisyfilt = tmf.lowpass(st_N_noisy,fcorner_low,stsamprate,order,zerophase=True)
                        st_Z_noisyfilt = tmf.lowpass(st_Z_noisy,fcorner_low,stsamprate,order,zerophase=True)
                        
                        st_E_noisyfilt.write(f'{param_dir}/processed_wfs/disp_noise/{run}/{stn}.LYE.mseed', format='MSEED')
                        st_N_noisyfilt.write(f'{param_dir}/processed_wfs/disp_noise/{run}/{stn}.LYN.mseed', format='MSEED')
                        st_Z_noisyfilt.write(f'{param_dir}/processed_wfs/disp_noise/{run}/{stn}.LYZ.mseed', format='MSEED')
                        
                        
                    ####################### Horizontal calc #######################
                        
                    # Take the min time of E and N start times to be the start
                    EN_start = np.min([E_start,N_start])
                    
                    # Take the max time of E and N end times to be the end
                    EN_end = np.max([E_end,N_end])
                    
                    # Get the duration to be the time between these
                    EN_Td = EN_end - EN_start
                    horiz_Td_list = np.append(horiz_Td_list,EN_Td)
            
                        
                    ####################### 3 component calc ######################
            
                    # Take the min time of the E,N,Z start times to be the start
                    ENZ_start = np.min([E_start,N_start,Z_start])
                    
                    # Take the max of the E,N,Z end times to be the end
                    ENZ_end = np.max([E_end,N_end,Z_end])
                    
                    # Get the duration to be the time between these
                    ENZ_Td = ENZ_end - ENZ_start
                    comp3_Td_list = np.append(comp3_Td_list,ENZ_Td)
                    
                    
                    ############################ Waveforms ############################
        
                    ## Append tr data to lists to make wf comparison plots
                        
                    if data == 'sm':
                        
                        # wf_amps = avg.get_eucl_norm_3comp(E_record[0].data, N_record[0].data, Z_record[0].data)
                        wf_amps = compute_rotd50(E_record[0].data,N_record[0].data)
                        syn_times.append(E_record[0].times('matplotlib'))
                        syn_amps_E.append(E_record[0].data.tolist())
                        syn_amps_N.append(N_record[0].data.tolist())
                        syn_amps_Z.append(Z_record[0].data.tolist())
                        syn_amps_avg.append(wf_amps.tolist())
            
            
                    ######################## Intensity Measures #######################
                    
                    # print(f'...computing IMs for {parameter} {project} {stn}')
                    
                    if data == 'gnss':
                        
                        # Shorten waveforms to avoid calculating PGD on long period
                            # noise for some stations and for calculating spectra
                        tr_E_short = st_E_noisyfilt[0].trim(endtime=UTCDateTime("2010-10-25T14:47:02"))
                        tr_N_short = st_N_noisyfilt[0].trim(endtime=UTCDateTime("2010-10-25T14:47:02"))
                        tr_Z_short = st_Z_noisyfilt[0].trim(endtime=UTCDateTime("2010-10-25T14:47:02"))
                        
                        ######################### Displacement ########################
                        
                        # print(f'....working on disp IMs for {run} {stn}')
                    
                        # Calculate PGD
                        eucnorm = avg.get_eucl_norm_3comp(tr_E_short.data, tr_N_short.data, tr_Z_short.data)
                        pgd = np.max(np.abs(eucnorm))
                        pgd_list = np.append(pgd_list,pgd)
                        
                        syn_amps_E.append(st_E_noisyfilt[0].data.tolist())
                        syn_amps_N.append(st_N_noisyfilt[0].data.tolist())
                        syn_amps_Z.append(st_Z_noisyfilt[0].data.tolist())
                        syn_amps_avg.append(eucnorm.tolist())
                        syn_times.append(tr_E_short.times('matplotlib'))
                        
                        # Calculate tPGD from origin and p-arrival
                        tPGD = IM_fns.calc_time_to_peak(pgd, tr_E_short,np.abs(eucnorm),origin,hypdist)
                        tPGD_list = np.append(tPGD_list,tPGD)
            
                        # Disp Spectra
                        bins, E_spec_data = IM_fns.calc_spectra(st_E_noisyfilt, data)
                        bins, N_spec_data = IM_fns.calc_spectra(st_N_noisyfilt, data)
                        bins, Z_spec_data = IM_fns.calc_spectra(st_Z_noisyfilt, data)
                        
                        bins_trim, E_spec_data_trim = IM_fns.calc_spectra(Stream(tr_E_short), data)
                        bins_trim, N_spec_data_trim = IM_fns.calc_spectra(Stream(tr_N_short), data)
                        bins_trim, Z_spec_data_trim = IM_fns.calc_spectra(Stream(tr_Z_short), data)
                        
                        # Get avg of horizontals
                        # NE_data = (E_spec_data - N_spec_data)/(np.log(E_spec_data)-np.log(N_spec_data))
                        NE_data = np.sqrt(E_spec_data**2 + N_spec_data**2)
                        NE_data_trim = np.sqrt(E_spec_data_trim**2 + N_spec_data_trim**2)
                        
                        # Append spectra to lists to make spectra comparison plots
                        syn_freqs.append(bins)
                        syn_spec.append(NE_data.tolist())
                        syn_freqs_trim.append(bins_trim)
                        syn_spec_trim.append(NE_data_trim.tolist())
                        hypdists.append(hypdist)
                        
                        # Save spectra as .out file
                        if not path.exists(f'{param_dir}/spectra/{run}/disp/'):
                            makedirs(f'{param_dir}/spectra/{run}/disp/')
                            
                        outfile = open(f'{param_dir}/spectra/{run}/disp/{stnetwork}_{stn}_LYNE.out', 'w')
                        file_data = np.array([bins, E_spec_data, N_spec_data, Z_spec_data])
                        file_data = file_data.T
                        outfile.write('#bins \t \t disp_spec_E_m \t disp_spec_N_m \t disp_spec_Z_m.s \n')
                        np.savetxt(outfile, file_data, fmt=['%E', '%E', '%E', '%E'], delimiter='\t')
                        outfile.close()
                        
                        outfile = open(f'{param_dir}/spectra/{run}/disp/{stnetwork}_{stn}_LYNE_trim.out', 'w')
                        file_data = np.array([bins_trim, E_spec_data_trim, N_spec_data_trim, Z_spec_data_trim])
                        file_data = file_data.T
                        outfile.write('#bins \t \t disp_spec_E_m \t disp_spec_N_m \t disp_spec_Z_m.s \n')
                        np.savetxt(outfile, file_data, fmt=['%E', '%E', '%E', '%E'], delimiter='\t')
                        outfile.close()
        
                        
                    if data == 'sm':
                        
                        # Shorten waveforms to avoid calculating PGD on long period
                            # noise for some stations and for calculating spectra
                            
                        tr_E_short = E_record[0].copy()
                        tr_N_short = N_record[0].copy()
                        tr_Z_short = Z_record[0].copy()
                        tr_E_short = tr_E_short.trim(endtime=UTCDateTime("2010-10-25T14:47:02"))
                        tr_N_short = tr_N_short.trim(endtime=UTCDateTime("2010-10-25T14:47:02"))
                        tr_Z_short = tr_Z_short.trim(endtime=UTCDateTime("2010-10-25T14:47:02"))
                        
                        ######################### Acceleration ########################
                        
                        # print(f'....Processor {rank} working on acc IMs for {run} {stn}')
                       
                        # Calculate PGA
                        pga = np.max(np.abs(wf_amps))
                        pga_list = np.append(pga_list,pga)
                        
                        # Calcualte tPGA from origin and p-arrival
                        tPGA = IM_fns.calc_time_to_peak(pga, E_record[0],np.abs(wf_amps),origin,hypdist)
                        tPGA_list = np.append(tPGA_list,tPGA)
            
                        # Acc Spectra
                        bins, E_spec_data = IM_fns.calc_spectra(E_record, data)                
                        bins, N_spec_data = IM_fns.calc_spectra(N_record, data)
                        bins, Z_spec_data = IM_fns.calc_spectra(Z_record, data)
                        
                        bins_trim, E_spec_data_trim = IM_fns.calc_spectra(Stream(tr_E_short), data)                
                        bins_trim, N_spec_data_trim = IM_fns.calc_spectra(Stream(tr_N_short), data)
                        bins_trim, Z_spec_data_trim = IM_fns.calc_spectra(Stream(tr_Z_short), data)
                        
                        # Get avg of horizontals
                        # NE_data = (E_spec_data - N_spec_data)/(np.log(E_spec_data)-np.log(N_spec_data))
                        NE_data = np.sqrt(E_spec_data**2 + N_spec_data**2)
                        NE_data_trim = np.sqrt(E_spec_data_trim**2 + N_spec_data_trim**2)
                        
                        # Append spectra to lists to make spectra comparison plots
                        syn_freqs.append(bins)
                        syn_spec.append(NE_data.tolist())
                        syn_freqs_trim.append(bins_trim)
                        syn_spec_trim.append(NE_data_trim.tolist())
                        hypdists.append(hypdist)
                        
                        # Save spectra as .out file
                        if not path.exists(f'{param_dir}/spectra/{run}/acc/'):
                            makedirs(f'{param_dir}/spectra/{run}/acc/')
                            
                        outfile = open(f'{param_dir}/spectra/{run}/acc/{stnetwork}_{stn}_HHNE.out', 'w')
                        file_data = np.array([bins, E_spec_data, N_spec_data, Z_spec_data],dtype=object)
                        file_data = file_data.T
                        outfile.write('#bins \t \t acc_spec_E_m/s \t acc_spec_N_m/s \t acc_spec_Z_m/s \n')
                        np.savetxt(outfile, file_data, fmt=['%E', '%E', '%E', '%E'], delimiter='\t')
                        outfile.close()
                        
                        outfile = open(f'{param_dir}/spectra/{run}/acc/{stnetwork}_{stn}_HHNE_trim.out', 'w')
                        file_data = np.array([bins_trim, E_spec_data_trim, N_spec_data_trim, Z_spec_data_trim],dtype=object)
                        file_data = file_data.T
                        outfile.write('#bins \t \t acc_spec_E_m/s \t acc_spec_N_m/s \t acc_spec_Z_m/s \n')
                        np.savetxt(outfile, file_data, fmt=['%E', '%E', '%E', '%E'], delimiter='\t')
                        outfile.close()
        
    
            ########################### Comparison Plots ##########################
            
            # print(f'....making comparison plots for {parameter} {project}')
            
            wf_type = obs_wf_dir.split('/')[-1]
            plot_dir = f'{param_dir}/plots'
            
            # Make spectra and wf comparison plots
            if data == 'gnss':
                
                # print(f'....Processor {rank} making gnss comparison plots')
                    
                ## Displacement
                comp.plot_spec_comp(plot_dir,syn_freqs,syn_spec,disp_obs_freqs,disp_obs_spec,stn_list,hypdists,'disp',home,parameter,project,run,'full')
                # comp.plot_spec_comp(plot_dir,syn_freqs_trim,syn_spec_trim,disp_obs_freqs_trim,disp_obs_spec_trim,stn_list,hypdists,'disp',home,parameter,project,run,'trim')
                
                # comp.plot_wf_comp(plot_dir,syn_times,syn_amps_E,stn_list,hypdists,'disp',wf_type,home,parameter,project,run,'E',E_record[0].times('UTCDateTime')[0],UTCDateTime("2010-10-25T14:47:02"))
                # comp.plot_wf_comp(plot_dir,syn_times,syn_amps_N,stn_list,hypdists,'disp',wf_type,home,parameter,project,run,'N',E_record[0].times('UTCDateTime')[0],UTCDateTime("2010-10-25T14:47:02"))
                # comp.plot_wf_comp(plot_dir,syn_times,syn_amps_Z,stn_list,hypdists,'disp',wf_type,home,parameter,project,run,'Z',E_record[0].times('UTCDateTime')[0],UTCDateTime("2010-10-25T14:47:02"))
                comp.plot_wf_comp(plot_dir,syn_times,syn_amps_avg,stn_list,hypdists,'disp',wf_type,home,parameter,project,run,'avg',E_record[0].times('UTCDateTime')[0],UTCDateTime("2010-10-25T14:47:02"))
            
            if data == 'sm':
                
                # print(f'....Processor {rank} making sm comparison plots')
                
                ## Acceleration 
                comp.plot_spec_comp(plot_dir,syn_freqs,syn_spec,acc_obs_freqs,acc_obs_spec,stn_list,hypdists,'acc',home,parameter,project,run,'full')
                # comp.plot_spec_comp(plot_dir,syn_freqs_trim,syn_spec_trim,acc_obs_freqs_trim,acc_obs_spec_trim,stn_list,hypdists,'acc',home,parameter,project,run,'trim')
                
                # comp.plot_wf_comp(plot_dir,syn_times,syn_amps_E,stn_list,hypdists,'acc',wf_type,home,parameter,project,run,'E',E_record[0].times('UTCDateTime')[0],E_record[0].times('UTCDateTime')[-1])
                # comp.plot_wf_comp(plot_dir,syn_times,syn_amps_N,stn_list,hypdists,'acc',wf_type,home,parameter,project,run,'N',E_record[0].times('UTCDateTime')[0],E_record[0].times('UTCDateTime')[-1])
                # comp.plot_wf_comp(plot_dir,syn_times,syn_amps_Z,stn_list,hypdists,'acc',wf_type,home,parameter,project,run,'Z',E_record[0].times('UTCDateTime')[0],E_record[0].times('UTCDateTime')[-1])
                comp.plot_wf_comp(plot_dir,syn_times,syn_amps_avg,stn_list,hypdists,'acc',wf_type,home,parameter,project,run,'avg',E_record[0].times('UTCDateTime')[0],E_record[0].times('UTCDateTime')[-1])
                
        
            ############################## Dataframe ##############################
            
            syn_spec = np.array(syn_spec)
            syn_spec_trim = np.array(syn_spec_trim)
            
            # Crete dictionary 
            if data == 'gnss':
                
                dataset_dict = {'eventname':eventnames,'country':countries, 'origintime':origintimes,
                                'hyplon':hyplons, 'hyplat':hyplats, 'hypdepth (km)':hypdepths,
                                'mw':mws, 'm0':m0s, 'network':networks, 'station':stations,
                                'station_type':stn_type_list, 'stlon':stlons, 'stlat':stlats, 'stelev':stelevs,
                                'mechanism':mechanisms, 'hypdist':hypdist_list, 'duration_e':E_Td_list,
                                'duration_n':N_Td_list, 'duration_z':Z_Td_list, 'duration_horiz':horiz_Td_list,
                                'duration_3comp':comp3_Td_list, 'pgd':pgd_list,'tPGD':tPGD_list,
                                'Spectra_Disp_Bin1_trim':syn_spec_trim[:,0],'Spectra_Disp_Bin2_trim':syn_spec_trim[:,1],
                                'Spectra_Disp_Bin3_trim':syn_spec_trim[:,2],'Spectra_Disp_Bin4_trim':syn_spec_trim[:,3],
                                'Spectra_Disp_Bin5_trim':syn_spec_trim[:,4],'Spectra_Disp_Bin6_trim':syn_spec_trim[:,5],
                                'Spectra_Disp_Bin7_trim':syn_spec_trim[:,6],'Spectra_Disp_Bin8_trim':syn_spec_trim[:,7],
                                'Spectra_Disp_Bin9_trim':syn_spec_trim[:,8],'Spectra_Disp_Bin10_trim':syn_spec_trim[:,9],
                                'Spectra_Disp_Bin1_full':syn_spec[:,0],'Spectra_Disp_Bin2_full':syn_spec[:,1],
                                'Spectra_Disp_Bin3_full':syn_spec[:,2],'Spectra_Disp_Bin4_full':syn_spec[:,3],
                                'Spectra_Disp_Bin5_full':syn_spec[:,4],'Spectra_Disp_Bin6_full':syn_spec[:,5],
                                'Spectra_Disp_Bin7_full':syn_spec[:,6],'Spectra_Disp_Bin8_full':syn_spec[:,7],
                                'Spectra_Disp_Bin9_full':syn_spec[:,8],'Spectra_Disp_Bin10_full':syn_spec[:,9]}
                
                # Create and save dataframe
                main_df = pd.DataFrame(data=dataset_dict)
                main_df.to_csv(gnss_flatfile_path,index=False)
        
            else:
                dataset_dict = {'eventname':eventnames,'country':countries, 'origintime':origintimes,
                                'hyplon':hyplons, 'hyplat':hyplats, 'hypdepth (km)':hypdepths,
                                'mw':mws, 'm0':m0s, 'network':networks, 'station':stations,
                                'station_type':stn_type_list, 'stlon':stlons, 'stlat':stlats, 'stelev':stelevs,
                                'mechanism':mechanisms, 'hypdist':hypdist_list, 'duration_e':E_Td_list,
                                'duration_n':N_Td_list, 'duration_z':Z_Td_list, 'duration_horiz':horiz_Td_list,
                                'duration_3comp':comp3_Td_list, 'pga':pga_list, 'tPGA':tPGA_list,
                                'Spectra_Acc_Bin1_trim':syn_spec_trim[:,0],'Spectra_Acc_Bin2_trim':syn_spec_trim[:,1],
                                'Spectra_Acc_Bin3_trim':syn_spec_trim[:,2],'Spectra_Acc_Bin4_trim':syn_spec_trim[:,3],
                                'Spectra_Acc_Bin5_trim':syn_spec_trim[:,4],'Spectra_Acc_Bin6_trim':syn_spec_trim[:,5],
                                'Spectra_Acc_Bin7_trim':syn_spec_trim[:,6],'Spectra_Acc_Bin8_trim':syn_spec_trim[:,7],
                                'Spectra_Acc_Bin9_trim':syn_spec_trim[:,8],'Spectra_Acc_Bin10_trim':syn_spec_trim[:,9],
                                'Spectra_Acc_Bin1_full':syn_spec[:,0],'Spectra_Acc_Bin2_full':syn_spec[:,1],
                                'Spectra_Acc_Bin3_full':syn_spec[:,2],'Spectra_Acc_Bin4_full':syn_spec[:,3],
                                'Spectra_Acc_Bin5_full':syn_spec[:,4],'Spectra_Acc_Bin6_full':syn_spec[:,5],
                                'Spectra_Acc_Bin7_full':syn_spec[:,6],'Spectra_Acc_Bin8_full':syn_spec[:,7],
                                'Spectra_Acc_Bin9_full':syn_spec[:,8],'Spectra_Acc_Bin10_full':syn_spec[:,9]}
                
                # Create and save dataframe
                main_df = pd.DataFrame(data=dataset_dict)
                main_df.to_csv(sm_flatfile_path,index=False)


############################### End Parallelization ###########################

#Set up empty array to gather data on
recvbuf=None
if rank == 0:
    recvbuf = np.empty(count*size, dtype=int)

comm.Gather(subdata, recvbuf, root=0)

    
